{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./PITdf.pkl','rb') as f:\n",
    "    PITdf = pickle.load(f)\n",
    "with open('./GREdf.pkl','rb') as f:\n",
    "    GREdf = pickle.load(f)\n",
    "with open('./JONdf.pkl','rb') as f:\n",
    "    JONdf = pickle.load(f)\n",
    "with open('./MGTdf.pkl','rb') as f:\n",
    "    MGTdf = pickle.load(f)\n",
    "with open('./WASdf.pkl','rb') as f:\n",
    "    WASdf = pickle.load(f)\n",
    "with open('./WHLdf.pkl','rb') as f:\n",
    "    WHLdf = pickle.load(f)\n",
    "with open('./PKSdf.pkl','rb') as f:\n",
    "    PKSdf = pickle.load(f)\n",
    "with open('./CBGdf.pkl','rb') as f:\n",
    "    CBGdf = pickle.load(f)\n",
    "with open('./STUdf.pkl','rb') as f:\n",
    "    STUdf = pickle.load(f)\n",
    "with open('./NPHdf.pkl','rb') as f:\n",
    "    NPHdf = pickle.load(f)\n",
    "with open('./ELVdf.pkl','rb') as f:\n",
    "    ELVdf = pickle.load(f)\n",
    "with open('./YGTdf.pkl','rb') as f:\n",
    "    YGTdf = pickle.load(f)\n",
    "with open('./NCSdf.pkl','rb') as f:\n",
    "    NCSdf = pickle.load(f)\n",
    "with open('./BUTdf.pkl','rb') as f:\n",
    "    BUTdf = pickle.load(f)\n",
    "with open('./KITdf.pkl','rb') as f:\n",
    "    KITdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  Day  Hour  Minute  DNI  Wind Speed  Wind Direction    wind_x  \\\n",
      "0  1998      1    1     0       0  0.0         0.6           241.0 -0.524772   \n",
      "1  1998      1    1     0      30  0.0         0.6           241.0 -0.524772   \n",
      "2  1998      1    1     1       0  0.0         0.6           238.0 -0.508829   \n",
      "3  1998      1    1     1      30  0.0         0.6           238.0 -0.508829   \n",
      "4  1998      1    1     2       0  0.0         0.6           225.8 -0.430146   \n",
      "\n",
      "     wind_y     day_x     day_y    time_x    time_y  max_possible_DNI  \\\n",
      "0 -0.290886  0.017213  0.999852  0.000000  1.000000               0.0   \n",
      "1 -0.290886  0.017213  0.999852  0.130526  0.991445               0.0   \n",
      "2 -0.317952  0.017213  0.999852  0.258819  0.965926               0.0   \n",
      "3 -0.317952  0.017213  0.999852  0.382683  0.923880               0.0   \n",
      "4 -0.418299  0.017213  0.999852  0.500000  0.866025               0.0   \n",
      "\n",
      "   cloudiness_factor  \n",
      "0           0.773816  \n",
      "1           0.020232  \n",
      "2           0.551991  \n",
      "3           0.019842  \n",
      "4           0.924428  \n"
     ]
    }
   ],
   "source": [
    "print(PITdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this attempt, I will use only the DNI from PGH plus the 6 closest cities (PIT, BUT, GRE, WAS, WHL, STU, ELV). The shape of this data will have each column be the DNI from a different city. The rows will be measurement instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367920, 6)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = np.concatenate((PITdf['DNI'].values.reshape(-1,1), BUTdf['DNI'].values.reshape(-1,1), \\\n",
    "                           GREdf['DNI'].values.reshape(-1,1), ELVdf['DNI'].values.reshape(-1,1), \\\n",
    "                           WHLdf['DNI'].values.reshape(-1,1), STUdf['DNI'].values.reshape(-1,1), ),axis = 1)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training purposes, I will use 5 years of data for training and 1 for testing. I will take this data from the first 6 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87600, 6)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_length = 365 * 48 * 1\n",
    "train_length = 365 * 48 * 5\n",
    "all_data = all_data[:(train_length + test_length), :]\n",
    "all_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now split the data into inputs and targets. My inputs will be the 6-dim data from time step t-1 and the target will be the DNI from PIT at time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334. 825. 181. 842. 849. 843.]\n",
      " [844. 840. 340. 856. 864. 857.]\n",
      " [832. 827. 829. 843. 852. 845.]\n",
      " [825. 817. 827. 404. 838. 829.]\n",
      " [790. 782. 793. 793. 805. 795.]\n",
      " [746. 738. 753. 749. 759. 751.]\n",
      " [672. 663. 678. 677. 688. 680.]\n",
      " [570. 557. 573. 578. 588. 582.]\n",
      " [388. 371. 386. 404. 419. 410.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "[844. 832. 825. 790. 746. 672. 570. 388.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "inputs = all_data[:-1,:]\n",
    "targets = all_data[1:,0]\n",
    "print(inputs[25:35,:])\n",
    "print(targets[25:35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87599, 6) (87599,)\n",
      "(0, 6) (0,)\n",
      "[[746. 738. 753. 749. 759. 751.]\n",
      " [672. 663. 678. 677. 688. 680.]\n",
      " [570. 557. 573. 578. 588. 582.]\n",
      " [388. 371. 386. 404. 419. 410.]\n",
      " [  0.   0.   0.   0.   0.   0.]] [672. 570. 388.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "X_train = inputs[:train_length,:]\n",
    "y_train = targets[:train_length]\n",
    "\n",
    "X_test = inputs[train_length:,:]\n",
    "y_test = targets[train_length:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train[30:35,:], y_train[30:35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaize input between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_normalized = scaler.fit(X_train)\n",
    "\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert np.array to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87599, 6]) torch.Size([87599])\n",
      "torch.Size([0, 6]) torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "X_train_normalized = torch.from_numpy(X_train_normalized).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train).float())\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test).float())\n",
    "\n",
    "print(X_train_normalized.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will attempt to build a class defining a FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.relu(self.fc3(x))\n",
    "net = Net(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(117719.4766, grad_fn=<MseLossBackward>)\n",
      "tensor(12065.2549, grad_fn=<MseLossBackward>)\n",
      "tensor(11835.0371, grad_fn=<MseLossBackward>)\n",
      "tensor(11729.2266, grad_fn=<MseLossBackward>)\n",
      "tensor(11699.1367, grad_fn=<MseLossBackward>)\n",
      "tensor(11693.2529, grad_fn=<MseLossBackward>)\n",
      "tensor(11689.8467, grad_fn=<MseLossBackward>)\n",
      "tensor(11685.6787, grad_fn=<MseLossBackward>)\n",
      "tensor(11681.0693, grad_fn=<MseLossBackward>)\n",
      "tensor(11676.3818, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    \n",
    "    y_pred = net(X_train_normalized)\n",
    "    \n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(train_loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87599,)\n",
      "(87599,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2.0000e+01, 1.3300e+02, 6.8300e+02, 3.0120e+03, 6.3500e+04,\n",
       "        1.5266e+04, 4.0180e+03, 7.9200e+02, 1.5500e+02, 2.0000e+01]),\n",
       " array([-881.72614   , -705.5662    , -529.40625   , -353.24634   ,\n",
       "        -177.08641   ,   -0.92648315,  175.23344   ,  351.39337   ,\n",
       "         527.5533    ,  703.71326   ,  879.87317   ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATuklEQVR4nO3df6zd9X3f8eerdkhZGmITLsiyvZmsXlsaKQGuwFXWaoszY5MuZlupHE2zlSFZi8iUqJtap5FGlzQSbGqzoqVUbvCwo7SEpY2wEqjjOkmnSfzwJTiAcagvhIZbu/i2JoSOlYjsvT/O5yZf7HPvPdf2Pfc6eT6kr873+/5+vue8z/cceN3v93zPcaoKSdKPth9b6AYkSQvPMJAkGQaSJMNAkoRhIEkCli50A2fqkksuqTVr1ix0G5J03njkkUf+uqpG+q07b8NgzZo1jI2NLXQbknTeSPIX063zNJEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjiPv4EszWbNji8uyOM+e+u7F+RxpbPhkYEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEliwDBIsizJ55J8I8mRJD+X5OIk+5McbbfL29gkuT3JeJLHklzVuZ9tbfzRJNs69auTPN62uT1Jzv1TlSRNZ9Ajg98B/qSqfhp4G3AE2AEcqKq1wIG2DLAJWNum7cAdAEkuBm4BrgWuAW6ZCpA2Zntnu41n97QkSXMxaxgkuQj4BeBOgKr6blV9G9gM7G7DdgM3tPnNwJ7qeRBYlmQFcB2wv6pOVtULwH5gY1t3UVU9UFUF7OnclyRpCAY5MngLMAn8jySPJvlUkjcAl1XVcYB2e2kbvxJ4rrP9RKvNVJ/oUz9Nku1JxpKMTU5ODtC6JGkQg4TBUuAq4I6quhL4P/zglFA//c731xnUTy9W7ayq0aoaHRkZmblrSdLABgmDCWCiqh5qy5+jFw7Pt1M8tNsTnfGrO9uvAo7NUl/Vpy5JGpJZw6Cq/gp4LslPtdJ64ElgLzB1RdA24N42vxfY2q4qWge82E4j7QM2JFnePjjeAOxr615Ksq5dRbS1c1+SpCEY9Ces/z3wmSQXAM8A76MXJPckuQn4FnBjG3sfcD0wDrzcxlJVJ5N8DDjYxn20qk62+fcDdwEXAve3SZI0JAOFQVUdAkb7rFrfZ2wBN09zP7uAXX3qY8BbB+lFknTu+Q1kSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYsAwSPJskseTHEoy1moXJ9mf5Gi7Xd7qSXJ7kvEkjyW5qnM/29r4o0m2depXt/sfb9vmXD9RSdL05nJk8E+r6u1VNdqWdwAHqmotcKAtA2wC1rZpO3AH9MIDuAW4FrgGuGUqQNqY7Z3tNp7xM5IkzdnZnCbaDOxu87uBGzr1PdXzILAsyQrgOmB/VZ2sqheA/cDGtu6iqnqgqgrY07kvSdIQDBoGBXwpySNJtrfaZVV1HKDdXtrqK4HnOttOtNpM9Yk+9dMk2Z5kLMnY5OTkgK1LkmazdMBx76iqY0kuBfYn+cYMY/ud768zqJ9erNoJ7AQYHR3tO0aSNHcDHRlU1bF2ewL4PL1z/s+3Uzy02xNt+ASwurP5KuDYLPVVfeqSpCGZNQySvCHJG6fmgQ3AE8BeYOqKoG3AvW1+L7C1XVW0DnixnUbaB2xIsrx9cLwB2NfWvZRkXbuKaGvnviRJQzDIaaLLgM+3qz2XAn9QVX+S5CBwT5KbgG8BN7bx9wHXA+PAy8D7AKrqZJKPAQfbuI9W1ck2/37gLuBC4P42SZKGZNYwqKpngLf1qf8NsL5PvYCbp7mvXcCuPvUx4K0D9CtJmgd+A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDGHMEiyJMmjSb7Qli9P8lCSo0k+m+SCVn99Wx5v69d07uPDrf5Ukus69Y2tNp5kx7l7epKkQczlyOCDwJHO8m3AJ6pqLfACcFOr3wS8UFU/CXyijSPJFcAW4GeBjcDvtoBZAnwS2ARcAby3jZUkDclAYZBkFfBu4FNtOcA7gc+1IbuBG9r85rZMW7++jd8M3F1Vr1TVN4Fx4Jo2jVfVM1X1XeDuNlaSNCSDHhn8N+BXgf/Xlt8MfLuqXm3LE8DKNr8SeA6grX+xjf9+/ZRtpqufJsn2JGNJxiYnJwdsXZI0m1nDIMkvAieq6pFuuc/QmmXdXOunF6t2VtVoVY2OjIzM0LUkaS6WDjDmHcB7klwP/DhwEb0jhWVJlra//lcBx9r4CWA1MJFkKfAm4GSnPqW7zXR1SdIQzHpkUFUfrqpVVbWG3gfAX66qfw18BfilNmwbcG+b39uWaeu/XFXV6lva1UaXA2uBh4GDwNp2ddIF7TH2npNnJ0kayCBHBtP5NeDuJL8JPArc2ep3Ap9OMk7viGALQFUdTnIP8CTwKnBzVX0PIMkHgH3AEmBXVR0+i74kSXM0pzCoqq8CX23zz9C7EujUMX8H3DjN9h8HPt6nfh9w31x6kSSdO34DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkhggDJL8eJKHk3w9yeEk/7nVL0/yUJKjST6b5IJWf31bHm/r13Tu68Ot/lSS6zr1ja02nmTHuX+akqSZDHJk8Arwzqp6G/B2YGOSdcBtwCeqai3wAnBTG38T8EJV/STwiTaOJFcAW4CfBTYCv5tkSZIlwCeBTcAVwHvbWEnSkMwaBtXzt23xdW0q4J3A51p9N3BDm9/clmnr1ydJq99dVa9U1TeBceCaNo1X1TNV9V3g7jZWkjQkA31m0P6CPwScAPYDTwPfrqpX25AJYGWbXwk8B9DWvwi8uVs/ZZvp6v362J5kLMnY5OTkIK1LkgYwUBhU1feq6u3AKnp/yf9Mv2HtNtOsm2u9Xx87q2q0qkZHRkZmb1ySNJA5XU1UVd8GvgqsA5YlWdpWrQKOtfkJYDVAW/8m4GS3fso209UlSUMyyNVEI0mWtfkLgXcBR4CvAL/Uhm0D7m3ze9sybf2Xq6pafUu72uhyYC3wMHAQWNuuTrqA3ofMe8/Fk5MkDWbp7ENYAexuV/38GHBPVX0hyZPA3Ul+E3gUuLONvxP4dJJxekcEWwCq6nCSe4AngVeBm6vqewBJPgDsA5YAu6rq8Dl7hpKkWc0aBlX1GHBln/oz9D4/OLX+d8CN09zXx4GP96nfB9w3QL+SpHngN5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRIDhEGS1Um+kuRIksNJPtjqFyfZn+Rou13e6klye5LxJI8luapzX9va+KNJtnXqVyd5vG1ze5LMx5OVJPU3yJHBq8B/qKqfAdYBNye5AtgBHKiqtcCBtgywCVjbpu3AHdALD+AW4FrgGuCWqQBpY7Z3ttt49k9NkjSoWcOgqo5X1dfa/EvAEWAlsBnY3YbtBm5o85uBPdXzILAsyQrgOmB/VZ2sqheA/cDGtu6iqnqgqgrY07kvSdIQzOkzgyRrgCuBh4DLquo49AIDuLQNWwk819lsotVmqk/0qUuShmTgMEjyE8AfAR+qqu/MNLRPrc6g3q+H7UnGkoxNTk7O1rIkaUADhUGS19ELgs9U1R+38vPtFA/t9kSrTwCrO5uvAo7NUl/Vp36aqtpZVaNVNToyMjJI65KkAQxyNVGAO4EjVfXbnVV7gakrgrYB93bqW9tVReuAF9tppH3AhiTL2wfHG4B9bd1LSda1x9rauS9J0hAsHWDMO4B/Azye5FCr/TpwK3BPkpuAbwE3tnX3AdcD48DLwPsAqupkko8BB9u4j1bVyTb/fuAu4ELg/jZJkoZk1jCoqv9N//P6AOv7jC/g5mnuaxewq099DHjrbL1IkuaH30CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJwX6bSNIcrNnxxQV53GdvffeCPK5+OHhkIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYoAwSLIryYkkT3RqFyfZn+Rou13e6klye5LxJI8luaqzzbY2/miSbZ361Ukeb9vcniTn+klKkmY2yJHBXcDGU2o7gANVtRY40JYBNgFr27QduAN64QHcAlwLXAPcMhUgbcz2znanPpYkaZ7NGgZV9b+Ak6eUNwO72/xu4IZOfU/1PAgsS7ICuA7YX1Unq+oFYD+wsa27qKoeqKoC9nTuS5I0JGf6mcFlVXUcoN1e2uorgec64yZabab6RJ96X0m2JxlLMjY5OXmGrUuSTnWuP0Dud76/zqDeV1XtrKrRqhodGRk5wxYlSac60zB4vp3iod2eaPUJYHVn3Crg2Cz1VX3qkqQhOtMw2AtMXRG0Dbi3U9/aripaB7zYTiPtAzYkWd4+ON4A7GvrXkqyrl1FtLVzX5KkIVk624Akfwj8E+CSJBP0rgq6FbgnyU3At4Ab2/D7gOuBceBl4H0AVXUyyceAg23cR6tq6kPp99O7YulC4P42SZKGaNYwqKr3TrNqfZ+xBdw8zf3sAnb1qY8Bb52tD0nS/PEbyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRID/IS1pPPDmh1fXLDHfvbWdy/YY+vc8MhAkmQYSJI8TaR5tpCnLiQNziMDSZJhIEkyDCRJGAaSJAwDSRKGgSSJRXRpaZKNwO8AS4BPVdWtC9ySpAEt1CXEfvP53FkUYZBkCfBJ4J8BE8DBJHur6smF7eyHh9f7S5rJoggD4BpgvKqeAUhyN7AZ+KEKA/+HLJ1b/h7TubNYwmAl8FxneQK49tRBSbYD29vi3yZ5agi9zdUlwF8vdBMDstf5Ya/zZ9H0m9tmHbJoeu34B9OtWCxhkD61Oq1QtRPYOf/tnLkkY1U1utB9DMJe54e9zp/zqd/zqVdYPFcTTQCrO8urgGML1Isk/chZLGFwEFib5PIkFwBbgL0L3JMk/chYFKeJqurVJB8A9tG7tHRXVR1e4LbO1KI+jXUKe50f9jp/zqd+z6deSdVpp+YlST9iFstpIknSAjIMJEmGwZlK8tkkh9r0bJJDrb4myf/trPu9zjZXJ3k8yXiS25P0u6R2Pnr9jSR/2enp+s66D7d+nkpyXae+sdXGk+wYRp/tcf9rkm8keSzJ55Msa/VFt1+n6X9B9tsM/axO8pUkR5IcTvLBVp/ze2JI/T7bXstDScZa7eIk+5McbbfLWz3t9R5v75erhtjnT3X23aEk30nyocW6XwdSVU5nOQG/BfynNr8GeGKacQ8DP0fvexX3A5uG1N9vAP+xT/0K4OvA64HLgafpfYC/pM2/BbigjbliSL1uAJa2+duA2xbrfu3Tx4Lttxl6WgFc1ebfCPx5e93n9J4YYr/PApecUvsvwI42v6Pznri+vd4B1gEPLeDr/lf0vtC1KPfrIJNHBmep/RX6y8AfzjJuBXBRVT1QvXfHHuCGIbQ4k83A3VX1SlV9Exin99Mg3/95kKr6LjD18yDzrqq+VFWvtsUH6X3nZFqLbL8u2H6bTlUdr6qvtfmXgCP0vvE/neneEwtpM7C7ze/mB6/vZmBP9TwILGvvh2FbDzxdVX8xw5jFuF9fwzA4ez8PPF9VRzu1y5M8muTPkvx8q62k9+W6KRPM/B/lufaBdii9a+owm/4/A7Jyhvqw/Vt6f/lNWYz7tWux7Le+kqwBrgQeaqW5vCeGpYAvJXkkvZ+fAbisqo5DL9yAS1t9oXudsoXX/jG4GPfrrAyDGST50yRP9Jm6f+29l9e+EY4Df7+qrgR+BfiDJBcx4E9uzFOvdwD/EHh76++3pjabpqeF7HVqzEeAV4HPtNKC7Nc5Wky9vEaSnwD+CPhQVX2Hub8nhuUdVXUVsAm4OckvzDB2oXslvS/Jvgf4n620WPfrrBbFl84Wq6p610zrkywF/iVwdWebV4BX2vwjSZ4G/hG9vwS6pzzO6U9uzNZrp+ffB77QFmf6GZB5+3mQAfbrNuAXgfXt1M+C7dc5WpQ/q5LkdfSC4DNV9ccAVfV8Z/2g74l5V1XH2u2JJJ+ndyrl+SQrqup4Ow10YjH02mwCvja1Pxfrfh2ERwZn513AN6rq+6cpkoyk9+8zkOQtwFrgmXZ4+1KSde1zhq3AvcNo8pTzqP8CeKLN7wW2JHl9kstbrw+zgD8Pkt4/cvRrwHuq6uVOfdHt1z4W3c+qtH1yJ3Ckqn67U5/re2IYvb4hyRun5uldTPBE62lbG7aNH7y+e4Gt7aqidcCLU6eThug1ZwYW434d2EJ/gn0+T8BdwL87pfavgMP0rhz4GvDPO+tG6b05ngb+O+0b4EPo89PA48Bj9N6UKzrrPtL6eYrOVTj0rtT487buI0Pcp+P0zq0eatPvLdb9Ok3/C7LfZujnH9M7HfFYZ59efybviSH0+pb2+n69vdYfafU3AweAo+324lYPvX8U6+n2XEaHvG//HvA3wJs6tUW3Xwed/DkKSZKniSRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEnA/wdWHaHBbpMInwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = net(X_train_normalized)\n",
    "y_pred_np = y_pred.detach().numpy()[:,0]\n",
    "y_train_np = y_train.detach().numpy()\n",
    "print(y_pred_np.shape)\n",
    "print(y_train_np.shape)\n",
    "err = np.subtract(y_train_np, y_pred_np)\n",
    "plt.hist(err)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
