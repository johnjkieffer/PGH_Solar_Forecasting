{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./PITdf.pkl','rb') as f:\n",
    "    PITdf = pickle.load(f)\n",
    "with open('./GREdf.pkl','rb') as f:\n",
    "    GREdf = pickle.load(f)\n",
    "with open('./JONdf.pkl','rb') as f:\n",
    "    JONdf = pickle.load(f)\n",
    "with open('./MGTdf.pkl','rb') as f:\n",
    "    MGTdf = pickle.load(f)\n",
    "with open('./WASdf.pkl','rb') as f:\n",
    "    WASdf = pickle.load(f)\n",
    "with open('./WHLdf.pkl','rb') as f:\n",
    "    WHLdf = pickle.load(f)\n",
    "with open('./PKSdf.pkl','rb') as f:\n",
    "    PKSdf = pickle.load(f)\n",
    "with open('./CBGdf.pkl','rb') as f:\n",
    "    CBGdf = pickle.load(f)\n",
    "with open('./STUdf.pkl','rb') as f:\n",
    "    STUdf = pickle.load(f)\n",
    "with open('./NPHdf.pkl','rb') as f:\n",
    "    NPHdf = pickle.load(f)\n",
    "with open('./ELVdf.pkl','rb') as f:\n",
    "    ELVdf = pickle.load(f)\n",
    "with open('./YGTdf.pkl','rb') as f:\n",
    "    YGTdf = pickle.load(f)\n",
    "with open('./NCSdf.pkl','rb') as f:\n",
    "    NCSdf = pickle.load(f)\n",
    "with open('./BUTdf.pkl','rb') as f:\n",
    "    BUTdf = pickle.load(f)\n",
    "with open('./KITdf.pkl','rb') as f:\n",
    "    KITdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367920\n",
      "   Year  Month  Day  Hour  Minute  DNI  Wind Speed  Wind Direction    wind_x  \\\n",
      "0  1998      1    1     0       0  0.0         0.6           241.0 -0.524772   \n",
      "1  1998      1    1     0      30  0.0         0.6           241.0 -0.524772   \n",
      "2  1998      1    1     1       0  0.0         0.6           238.0 -0.508829   \n",
      "3  1998      1    1     1      30  0.0         0.6           238.0 -0.508829   \n",
      "4  1998      1    1     2       0  0.0         0.6           225.8 -0.430146   \n",
      "\n",
      "     wind_y     day_x     day_y    time_x    time_y  max_possible_DNI  \\\n",
      "0 -0.290886  0.017213  0.999852  0.000000  1.000000               0.0   \n",
      "1 -0.290886  0.017213  0.999852  0.130526  0.991445               0.0   \n",
      "2 -0.317952  0.017213  0.999852  0.258819  0.965926               0.0   \n",
      "3 -0.317952  0.017213  0.999852  0.382683  0.923880               0.0   \n",
      "4 -0.418299  0.017213  0.999852  0.500000  0.866025               0.0   \n",
      "\n",
      "   cloudiness_factor  \n",
      "0           0.773816  \n",
      "1           0.020232  \n",
      "2           0.551991  \n",
      "3           0.019842  \n",
      "4           0.924428  \n"
     ]
    }
   ],
   "source": [
    "print(len(PITdf))\n",
    "print(PITdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let the 'DNI' be the only input and also be the target variable. This first trial, I will only use information from PIT, not any other cities. I will set aside the last year as the test set and use the first 5 years as training and the 6th year for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0. 159.   0. 580. 167. 252. 116.  34. 271. 363. 334. 844. 832.\n",
      " 825. 790. 746. 672. 570. 388.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "all_data = PITdf['DNI'].values\n",
    "all_data = all_data[:365*48*6]\n",
    "test_data_size = 365*48\n",
    "train_data = all_data[:-test_data_size]\n",
    "test_data = all_data[-test_data_size:]\n",
    "print(train_data[:48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will normalize the data between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training window. I will start with this being 4 (2 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw : i+tw+1]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([-1., -1., -1., -1.]), tensor([-1.])),\n",
       " (tensor([-1., -1., -1., -1.]), tensor([-1.])),\n",
       " (tensor([-1., -1., -1., -1.]), tensor([-1.])),\n",
       " (tensor([-1., -1., -1., -1.]), tensor([-1.])),\n",
       " (tensor([-1., -1., -1., -1.]), tensor([-1.]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                           torch.zeros(1,1,self.hidden_layer_size))\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.00011185\n",
      "epoch:   1 loss: 0.0001118457\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        \n",
    "        y_pred = model(seq)\n",
    "        \n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "        \n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "fut_pred = 365*48\n",
    "\n",
    "test_inputs = train_data[-train_window:].tolist()\n",
    "print(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(test_inputs[-train_window:])\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                       torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5253342986106873,\n",
       " 0.5253342986106873,\n",
       " 0.5253342986106873,\n",
       " 0.5253342986106873]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[fut_pred:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arrange()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
